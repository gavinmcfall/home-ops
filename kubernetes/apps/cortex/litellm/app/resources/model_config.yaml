router_model_list:
  - router_model_name: vision-router
    model_group: vision_tasks
    litellm_params:
      temperature: 0.5  # Temperature controls creativity: 0.0 = deterministic, 1.0 = creative
    metadata:
      label: "Vision Assistant"
      capabilities: ["chat", "vision"]

  - router_model_name: code-router
    model_group: code_pipeline
    litellm_params:
      temperature: 0.2  # Temperature controls creativity: 0.0 = deterministic, 1.0 = creative
    metadata:
      label: "Code Assistant"
      capabilities: ["chat", "code"]

  - router_model_name: education-router
    model_group: education_pipeline
    litellm_params:
      temperature: 0.6  # Temperature controls creativity: 0.0 = deterministic, 1.0 = creative
    metadata:
      label: "Education Assistant"
      capabilities: ["chat", "reasoning", "tutoring"]

model_list:
# Actual Model Definitions
# Each entry maps to a real provider + model pairing
# Models may define aliases for routing/fallback via `model_groups`

# Anthropic Models

  - model_name: "Anthopic: claude-3.5-haiku"
    provider: anthropic
    litellm_params:
      model: anthropic/claude-3-5-haiku-20241022
    api_key: ${ANTHROPIC_API_KEY}
    model_info:
      id: claude-3.5-haiku
      mode: completion
      input_cost_per_token: 0.0000008  # USD $0.80 per million tokens (input)
      output_cost_per_token: 0.000004  # USD $4.00 per million tokens (output)
      max_tokens: 200000  # Maximum context window: 200,000 tokens
    aliases: [general_anthropic, vision_anthropic]

# AWS Bedrock Models

  - model_name: "AWS Bedrock: claude-3-sonnet"
    provider: bedrock
    litellm_params:
      model: anthropic.claude-3-sonnet-20240229-v1:0
      region_name: ap-southeast-2
    api_key: ${AWS_BEDROCK_API_KEY}
    model_info:
      id: claude-3-sonnet
      mode: completion
      input_cost_per_token: 0.000003  # USD $3.00 per million tokens (input)
      output_cost_per_token: 0.000015  # USD $15.00 per million tokens (output)
      max_tokens: 200000  # Maximum context window: 200,000 tokens
    aliases: [general_bedrock, vision_bedrock]

# Google Models

  - model_name: "Google: gemini-1.5-pro"
    provider: google
    litellm_params:
      model: gemini-1.5-pro
    api_key: ${GOOGLE_API_KEY}
    model_info:
      id: gemini-1.5-pro
      mode: completion
      input_cost_per_token: 0.00000125  # USD $1.25 per million tokens (input)
      output_cost_per_token: 0.00000500  # USD $5.00 per million tokens (output)
      max_tokens: 32768  # Maximum context window: 32,768 tokens
    aliases: [general_gemini, vision_gemini]

# Groq Models

  - model_name: "Groq: Meta llama3-70b-8192"
    provider: groq
    litellm_params:
      model: groq/llama3-70b-8192
    api_key: ${GROQ_API_KEY}
    model_info:
      id: llama3-70b-8192
      mode: completion
      input_cost_per_token: 0.00000059  # USD $0.59 per million tokens (input)
      output_cost_per_token: 0.00000079  # USD $0.79 per million tokens (output)
      max_tokens: 32768  # Maximum context window: 32,768 tokens
    aliases: [code_fallback_groq]

# Open AI Models
  - model_name: "OpenAI: text-embedding-3-small"
    provider: openai
    litellm_params:
      model: text-embedding-3-small
      mode: embedding  # Required for embeddings
    api_key: ${OPENAI_API_KEY}
    model_info:
      id: text-embedding-3-small
      mode: embedding
      input_cost_per_token: 0.00000002  # USD $0.02 per million tokens (input)
      capabilities: [vision, chat]
    aliases: [embedding_openai]

  - model_name: "OpenAI: gpt-4.1-mini"
    provider: openai
    litellm_params:
      model: gpt-4.1-mini
    api_key: ${OPENAI_API_KEY}
    model_info:
      id: gpt-4.1-mini
      mode: completion
      input_cost_per_token: 0.0000004  # USD $0.40 per million tokens (input)
      output_cost_per_token: 0.0000016  # USD $1.60 per million tokens (output)
      max_tokens: 1047576  # Maximum context window: 1,047,576 tokens
    aliases: [gpt-4.1, general_openai, vision_openai]

  - model_name: "OpenAI: gpt-4o"
    provider: openai
    litellm_params:
      model: gpt-4o
    api_key: ${OPENAI_API_KEY}
    model_info:
      id: gpt-4o
      mode: completion
      input_cost_per_token: 0.0000005   # USD $0.50 per million tokens (input)
      output_cost_per_token: 0.0000015  # USD $1.50 per million tokens (output)
      max_tokens: 128000
    aliases: [general_openai_4o, vision_openai_4o, education_4o]


# TogetherAI Models

  - model_name: "TogetherAI: Qwen2.5-Coder-32B-Instruct"
    provider: togetherai
    litellm_params:
      model: together_ai/Qwen/Qwen2.5-Coder-32B-Instruct
    api_key: ${TOGETHER_API_KEY}
    model_info:
      id: Qwen2.5-Coder-32B-Instruct
      mode: completion
      input_cost_per_token: 0.0000008  # USD $0.80 per million tokens (input)
      output_cost_per_token: 0.0000008  # USD $0.80 per million tokens (output)
      max_tokens: 16384
    aliases: [code_fallback_together]

# xAI Models

  - model_name: "xAI: grok-3-mini-beta"
    provider: xai
    litellm_params:
      model: xai/grok-3-mini-beta
      api_base: "https://api.x.ai/v1"  # Required endpoint for xAI
    api_key: ${XAI_API_KEY}
    model_info:
      id: grok-3-mini-beta
      mode: completion
      input_cost_per_token: 0.0000003  # USD $0.30 per million tokens (input)
      output_cost_per_token: 0.0000005  # USD $0.50 per million tokens (output)
      max_tokens: 131072  # Maximum context window: 131,072 tokens
    aliases: [general_xai, vision_xai]


# Fallback Groups
# Each group is a list of model aliases (not full names!)
# These groups are referenced by `router_model_list` virtual models

model_groups:
  code_pipeline:
    - code_fallback_groq            # Fast + cheap reasoning for code
    - code_fallback_together        # Big context + strong code skills

  general_tasks:
    - general_openai_4o              # GPT-4o – multilingual, expressive
    - general_openai                # GPT-4.1 Mini – strong balance of capability and cost
    - general_anthropic             # Claude 3.5 – ideal for thoughtful reasoning and tone
    - general_gemini                # Gemini – strong reasoning and multi-modal fallback
    - general_bedrock               # Claude 3.0 (Bedrock) – secondary fallback
    - general_xai                   # Grok 3 – experimental fallback

  vision_tasks:
    - vision_openai_4o              # GPT-4o – best visual model for accuracy
    - vision_openai                   # GPT-4.1 Mini – vision-capable fallback
    - vision_anthropic              # Claude 3.5 – vision-capable fallback
    - vision_gemini                 # Gemini – multimodal assistant
    - vision_xai                    # Grok 3 – visual reasoning backup
    - vision_bedrock                # Claude 3.0 (Bedrock) – vision fallback

  education_pipeline:
    - education_4o                  # GPT-4o – ideal for tutoring with language diversity
    - general_openai                # GPT-4.1 Mini – ideal for tutoring
    - general_anthropic             # Claude 3.5 – empathetic and capable in tutoring
    - general_gemini                # Gemini – logical fallback
    - general_bedrock               # Claude 3.0 (Bedrock) – stable backup
    - general_xai                   # Grok 3 – fallback if others fail
