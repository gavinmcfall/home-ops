include:
  - model_config.yaml

general_settings:
  proxy_batch_write_at: 60
  database_connection_pool_limit: 10

  disable_spend_logs: false
  disable_error_logs: false

  background_health_checks: false
  health_check_interval: 300

  store_model_in_db: true

litellm_settings:
  proxy_server: true
  request_timeout: 600
  json_logs: true
  # enable_preview_features: true
  redact_user_api_key_info: true
  turn_off_message_logging: false
  set_verbose: true

  # Caching settings
  cache: true
  cache_params:
    type: qdrant-semantic        # redis, s3, redis-semantic, qdrant-semantic, disk, () not specificed = In memory

    # https://docs.litellm.ai/docs/caching/all_caches#updating-cache-params-redis-host-port-etc

    # Optional - Qdrant Semantic Cache Settings
    qdrant_semantic_cache_embedding_model: text-embedding-3-small # the model should be defined on the model_list
    qdrant_collection_name: litellm_cache
    qdrant_quantization_config: binary
    similarity_threshold: 0.8   # similarity threshold for semantic cache

    # Common Cache settings
    # Optional - Supported call types for caching

    supported_call_types: ["acompletion", "atext_completion", "aembedding", "atranscription"]
                          # /chat/completions, /completions, /embeddings, /audio/transcriptions
    mode: default_on # if default_off, you need to opt in to caching on a per call basis
    ttl: 600 # ttl for caching



router:
  - destination: vision_openai
    if:
      contains:
        - "data:image"
        - "image analysis"
        - "describe this image"
        - "photo"
        - "diagram"

router_settings:
  fallbacks:
    gpt-4-turbo:
      - claude-3.5-sonnet
      - gemini-1.5-pro
      - grok-1.5
      - claude-3-sonnet
    claude-3.5-sonnet:
      - gemini-1.5-pro
      - grok-1.5
      - gpt-4-turbo
    gemini-1.5-pro:
      - gpt-4-turbo
      - claude-3.5-sonnet
    grok-1.5:
      - gpt-4-turbo
      - claude-3.5-sonnet
    claude-3-sonnet:
      - gpt-4-turbo
      - gemini-1.5-pro
    deepseek-coder-33b-instruct:
      - llama3-groq-70b-8192
      - gpt-4-turbo
    llama3-groq-70b-8192:
      - gpt-4-turbo
