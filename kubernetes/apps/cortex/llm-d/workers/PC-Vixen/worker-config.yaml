# LLM-D Worker Configuration
# Generated: 2025-08-09 16:13:05
# Host: VIXENPC
# GPU: NVIDIA GeForce RTX 4080 SUPER (16 GB)
# Tier: mid-range

worker:
  name: "vixenpc"
  labels:
    owner: "NZVixen"
    gpu_type: "mid-range"
    gpu_model: "NVIDIA_GeForce_RTX_4080_SUPER"
    location: "office"
    platform: "windows"

  server:
    url: "https://llm-d-workers.${SECRET_DOMAIN}"
    token: "${LLMD_WORKER_TOKEN}"
    heartbeat_interval: 30

  resources:
    gpu:
      device_ids: [0]
      memory_fraction: 0.85
    cpu:
      cores: 8
    memory:
      limit_gb: 32

  models:
    cache_dir: "C:\\llm-d\\models"
    preload:
    - "mistral-22b"
    max_loaded: 1
    offload_timeout: 600

  performance:
    batch_size: 4
    max_sequences: 2
    use_flash_attention: true
    quantization: "int8"

  monitoring:
    prometheus_port: 9091
    enable_gpu_metrics: true

# Recommended models for this configuration:
# - llama-3.2-70b (int8 quantized)
# - mistral-22b (int8 quantized)
# - deepseek-coder-33b (int8 quantized)
# - llama-3.2-13b (full precision)
