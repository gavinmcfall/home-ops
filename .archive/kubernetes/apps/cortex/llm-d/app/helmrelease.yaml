---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s/helm-charts/main/charts/other/app-template/schemas/helmrelease-helm-v2.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app llm-d
spec:
  interval: 30m
  chart:
    spec:
      chart: app-template
      version: 3.7.3
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      strategy: rollback
      retries: 3
  dependsOn:
    - name: rook-ceph-cluster
      namespace: rook-ceph
    - name: volsync
      namespace: volsync-system
  values:
    controllers:
      llm-d:
        annotations:
          reloader.stakater.com/auto: "true"
        initContainers:
          init-db:
            image:
              repository: ghcr.io/home-operations/postgres-init
              tag: 17.6.0@sha256:86a1992d46273c58fd4ad95b626081dfaabfe16bd56944675169e406d1a660dd
            envFrom: &envFrom
              - secretRef:
                  name: llm-d-secret
        containers:
          app:
            image:
              repository: ghcr.io/llm-d-ai/llm-d-server
              tag: latest
            env:
              TZ: ${TIMEZONE}
              LLMD_MODE: server
              LLMD_PORT: &port 8080
              LLMD_HOST: 0.0.0.0
              LLMD_LOG_LEVEL: debug
              LLMD_ENABLE_METRICS: "true"
              LLMD_METRICS_PORT: &metricsPort 9090
              LLMD_WORKER_PORT: &workerPort 8081
              # Model management
              LLMD_MODEL_PATH: /models
              LLMD_CACHE_PATH: /cache
              # Worker management
              LLMD_WORKER_TIMEOUT: "300"
              LLMD_WORKER_HEARTBEAT_INTERVAL: "30"
              # Queue settings
              LLMD_QUEUE_TYPE: redis
              LLMD_REDIS_URL: redis://dragonfly.database.svc.cluster.local:6379
            envFrom: *envFrom
            ports:
              - name: http
                containerPort: *port
              - name: metrics
                containerPort: *metricsPort
              - name: workers
                containerPort: *workerPort
            probes:
              liveness:
                enabled: true
                custom: true
                spec:
                  httpGet:
                    path: /health
                    port: *port
                  initialDelaySeconds: 30
                  periodSeconds: 60
                  timeoutSeconds: 10
                  failureThreshold: 3
              readiness:
                enabled: true
                custom: true
                spec:
                  httpGet:
                    path: /ready
                    port: *port
                  initialDelaySeconds: 5
                  periodSeconds: 10
                  timeoutSeconds: 5
                  failureThreshold: 3
            securityContext:
              allowPrivilegeEscalation: false
              readOnlyRootFilesystem: true
              capabilities: { drop: ["ALL"] }
            resources:
              requests:
                cpu: 100m
                memory: 512Mi
              limits:
                memory: 2Gi

    defaultPodOptions:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        fsGroupChangePolicy: OnRootMismatch
        seccompProfile: { type: RuntimeDefault }

    service:
      app:
        controller: *app
        ports:
          http:
            primary: true
            port: *port
          metrics:
            port: *metricsPort
          workers:
            port: *workerPort

    ingress:
      app:
        annotations:
          external-dns.alpha.kubernetes.io/target: internal.${SECRET_DOMAIN}
        className: internal
        hosts:
          - host: "llm-d.${SECRET_DOMAIN}"
            paths:
              - path: /
                service:
                  identifier: app
                  port: http

    persistence:
      models:
        existingClaim: llm-d-models
        globalMounts:
          - path: /models
      cache:
        existingClaim: llm-d-cache
        globalMounts:
          - path: /cache
      config:
        type: configMap
        name: llm-d-configmap
        globalMounts:
          - path: /app/config.yaml
            subPath: config.yaml
            readOnly: true

    serviceMonitor:
      app:
        serviceName: llm-d
        endpoints:
          - port: metrics
            scheme: http
            path: /metrics
            interval: 30s
